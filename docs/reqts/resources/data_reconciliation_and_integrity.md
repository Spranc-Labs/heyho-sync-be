# Data Reconciliation and Integrity Strategy

This document details the backend principles required to handle data synchronization from multiple clients (e.g., different browsers/laptops) for a single user, ensuring a consistent, complete, and duplicate-free dataset.

This builds upon the architecture defined in `token_and_sync_strategy.md`.

## Core Backend Design Principles

To correctly handle data arriving from different clients at different times, the backend must adhere to the following principles during data ingestion and processing.

### 1. Idempotency via Unique Client-Side IDs

**Problem:** A client might send the same batch of data multiple times due to network errors or other interruptions. We must not create duplicate records.

**Solution:**
*   Every single record generated by the client (e.g., a `pageVisit`) **must** be assigned a unique identifier (UUID) on the client-side before it is ever synced.
*   The backend's data ingestion process **must** be idempotent. It will use an "upsert" (update or insert) strategy based on this unique ID.

**Flow:**
1.  Backend receives a record with UUID `xyz-123`.
2.  It checks the database for a record with this ID.
3.  **If it does not exist,** it inserts the new record.
4.  **If it already exists,** it skips the record (or updates it if the new record contains more recent information).

This guarantees that data can be safely re-sent without corrupting the user's history.

### 2. Timestamp-based Ordering for Continuity

**Problem:** A user might sync data from their work laptop (used yesterday) after syncing data from their home laptop (used an hour ago). The data will arrive at the backend out of chronological order.

**Solution:**
*   The backend **must not** rely on the server's received time (`created_at`) to order user activity.
*   All data processing, analysis, and presentation **must** be ordered by the client-side timestamp (e.g., `visited_at` or `event_timestamp`) that marks when the event actually occurred.

This ensures that a user's history is always presented as a coherent, continuous timeline, regardless of which device the data came from or when it was synced.

## Use Case Scenario: Multi-Device Sync

Let's walk through the user journey to see how these principles apply.

1.  **Initial State:**
    *   **Laptop A:** The user is logged in. Data is synced regularly.
    *   **Laptop B:** The user is **not** logged in. They browse for several days, and the extension stores this history in its local browser storage. The backend knows nothing about this data.

2.  **Login on Second Device:**
    *   The user logs into their existing account on **Laptop B**.
    *   The extension on Laptop B receives the authentication JWT and sees that it has a backlog of local data to sync.

3.  **Reconciliation Sync:**
    *   The extension on Laptop B sends its entire local history (e.g., hundreds of records, each with a unique ID and a client-side timestamp) to the backend's sync endpoint.

4.  **Backend Processing:**
    *   The backend receives the large batch of historical data for the user.
    *   For each record in the batch, it performs the **idempotent upsert** based on the record's unique ID.
    *   The records are saved. Even though they arrived today, they contain timestamps from previous days.

## Final Result

The user's account now contains the complete history from both laptops. When the user views their activity timeline, the backend queries and sorts all events by their `event_timestamp`, presenting a single, continuous, and accurate history with no duplicates.
